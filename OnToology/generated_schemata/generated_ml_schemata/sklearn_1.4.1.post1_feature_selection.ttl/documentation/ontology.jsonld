[ {
  "@id" : "_:genid1",
  "@type" : [ "http://www.w3.org/2002/07/owl#Ontology" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Chi2Method",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Compute chi-squared stats between each non-negative feature and class.\n\nThis score can be used to select the `n_features` features with the\nhighest values for the test chi-squared statistic from X, which must\ncontain only **non-negative features** such as booleans or frequencies\n(e.g., term counts in document classification), relative to the classes.\n\nRecall that the chi-square test measures dependence between stochastic\nvariables, so using this function \"weeds out\" the features that are the\nmost likely to be independent of class and therefore irrelevant for\nclassification.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples, n_features)\n    Sample vectors.\n\ny : array-like of shape (n_samples,)\n    Target vector (class labels).\n\nReturns\n-------\nchi2 : ndarray of shape (n_features,)\n    Chi2 statistics for each feature.\n\np_values : ndarray of shape (n_features,)\n    P-values for each feature.\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\n\nNotes\n-----\nComplexity of this algorithm is O(n_classes * n_features).\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.feature_selection import chi2\n>>> X = np.array([[1, 1, 3],\n...               [0, 1, 5],\n...               [5, 4, 1],\n...               [6, 6, 2],\n...               [1, 4, 0],\n...               [0, 0, 0]])\n>>> y = np.array([1, 1, 0, 0, 2, 2])\n>>> chi2_stats, p_values = chi2(X, y)\n>>> chi2_stats\narray([15.3...,  6.5       ,  8.9...])\n>>> p_values\narray([0.0004..., 0.0387..., 0.0116... ])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FClassifMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Compute the ANOVA F-value for the provided sample.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples, n_features)\n    The set of regressors that will be tested sequentially.\n\ny : array-like of shape (n_samples,)\n    The target vector.\n\nReturns\n-------\nf_statistic : ndarray of shape (n_features,)\n    F-statistic for each feature.\n\np_values : ndarray of shape (n_features,)\n    P-values associated with the F-statistic.\n\nSee Also\n--------\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\n\nExamples\n--------\n>>> from sklearn.datasets import make_classification\n>>> from sklearn.feature_selection import f_classif\n>>> X, y = make_classification(\n...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n...     shuffle=False, random_state=42\n... )\n>>> f_statistic, p_values = f_classif(X, y)\n>>> f_statistic\narray([2.2...e+02, 7.0...e-01, 1.6...e+00, 9.3...e-01,\n       5.4...e+00, 3.2...e-01, 4.7...e-02, 5.7...e-01,\n       7.5...e-01, 8.9...e-02])\n>>> p_values\narray([7.1...e-27, 4.0...e-01, 1.9...e-01, 3.3...e-01,\n       2.2...e-02, 5.7...e-01, 8.2...e-01, 4.5...e-01,\n       3.8...e-01, 7.6...e-01])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FRegressionMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Univariate linear regression tests returning F-statistic and p-values.\n\nQuick linear model for testing the effect of a single regressor,\nsequentially for many regressors.\n\nThis is done in 2 steps:\n\n1. The cross correlation between each regressor and the target is computed\n   using :func:`r_regression` as::\n\n       E[(X[:, i] - mean(X[:, i])) * (y - mean(y))] / (std(X[:, i]) * std(y))\n\n2. It is converted to an F score and then to a p-value.\n\n:func:`f_regression` is derived from :func:`r_regression` and will rank\nfeatures in the same order if all the features are positively correlated\nwith the target.\n\nNote however that contrary to :func:`f_regression`, :func:`r_regression`\nvalues lie in [-1, 1] and can thus be negative. :func:`f_regression` is\ntherefore recommended as a feature selection criterion to identify\npotentially predictive feature for a downstream classifier, irrespective of\nthe sign of the association with the target variable.\n\nFurthermore :func:`f_regression` returns p-values while\n:func:`r_regression` does not.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples, n_features)\n    The data matrix.\n\ny : array-like of shape (n_samples,)\n    The target vector.\n\ncenter : bool, default=True\n    Whether or not to center the data matrix `X` and the target vector `y`.\n    By default, `X` and `y` will be centered.\n\nforce_finite : bool, default=True\n    Whether or not to force the F-statistics and associated p-values to\n    be finite. There are two cases where the F-statistic is expected to not\n    be finite:\n\n    - when the target `y` or some features in `X` are constant. In this\n      case, the Pearson's R correlation is not defined leading to obtain\n      `np.nan` values in the F-statistic and p-value. When\n      `force_finite=True`, the F-statistic is set to `0.0` and the\n      associated p-value is set to `1.0`.\n    - when a feature in `X` is perfectly correlated (or\n      anti-correlated) with the target `y`. In this case, the F-statistic\n      is expected to be `np.inf`. When `force_finite=True`, the F-statistic\n      is set to `np.finfo(dtype).max` and the associated p-value is set to\n      `0.0`.\n\n    .. versionadded:: 1.1\n\nReturns\n-------\nf_statistic : ndarray of shape (n_features,)\n    F-statistic for each feature.\n\np_values : ndarray of shape (n_features,)\n    P-values associated with the F-statistic.\n\nSee Also\n--------\nr_regression: Pearson's R between label/feature for regression tasks.\nf_classif: ANOVA F-value between label/feature for classification tasks.\nchi2: Chi-squared stats of non-negative features for classification tasks.\nSelectKBest: Select features based on the k highest scores.\nSelectFpr: Select features based on a false positive rate test.\nSelectFdr: Select features based on an estimated false discovery rate.\nSelectFwe: Select features based on family-wise error rate.\nSelectPercentile: Select features based on percentile of the highest\n    scores.\n\nExamples\n--------\n>>> from sklearn.datasets import make_regression\n>>> from sklearn.feature_selection import f_regression\n>>> X, y = make_regression(\n...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n... )\n>>> f_statistic, p_values = f_regression(X, y)\n>>> f_statistic\narray([1.2...+00, 2.6...+13, 2.6...+00])\n>>> p_values\narray([2.7..., 1.5..., 1.0...])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelection",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GenericUnivariateSelectMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Univariate feature selector with configurable strategy.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues). For modes 'percentile' or 'kbest' it can return\n    a single array scores.\n\nmode : {'percentile', 'k_best', 'fpr', 'fdr', 'fwe'}, default='percentile'\n    Feature selection mode. Note that the `'percentile'` and `'kbest'`\n    modes are supporting unsupervised feature selection (when `y` is `None`).\n\nparam : \"all\", float or int, default=1e-5\n    Parameter of the corresponding mode.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores, None if `score_func` returned scores only.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nmutual_info_classif : Mutual information for a discrete target.\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\nmutual_info_regression : Mutual information for a continuous target.\nSelectPercentile : Select features based on percentile of the highest\n    scores.\nSelectKBest : Select features based on the k highest scores.\nSelectFpr : Select features based on a false positive rate test.\nSelectFdr : Select features based on an estimated false discovery rate.\nSelectFwe : Select features based on family-wise error rate.\n\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import GenericUnivariateSelect, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)\n>>> X_new = transformer.fit_transform(X, y)\n>>> X_new.shape\n(569, 20)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Estimate mutual information for a discrete target variable.\n\nMutual information (MI) [1]_ between two random variables is a non-negative\nvalue, which measures the dependency between the variables. It is equal\nto zero if and only if two random variables are independent, and higher\nvalues mean higher dependency.\n\nThe function relies on nonparametric methods based on entropy estimation\nfrom k-nearest neighbors distances as described in [2]_ and [3]_. Both\nmethods are based on the idea originally proposed in [4]_.\n\nIt can be used for univariate features selection, read more in the\n:ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples, n_features)\n    Feature matrix.\n\ny : array-like of shape (n_samples,)\n    Target vector.\n\ndiscrete_features : 'auto', bool or array-like, default='auto'\n    If bool, then determines whether to consider all features discrete\n    or continuous. If array, then it should be either a boolean mask\n    with shape (n_features,) or array with indices of discrete features.\n    If 'auto', it is assigned to False for dense `X` and to True for\n    sparse `X`.\n\nn_neighbors : int, default=3\n    Number of neighbors to use for MI estimation for continuous variables,\n    see [2]_ and [3]_. Higher values reduce variance of the estimation, but\n    could introduce a bias.\n\ncopy : bool, default=True\n    Whether to make a copy of the given data. If set to False, the initial\n    data will be overwritten.\n\nrandom_state : int, RandomState instance or None, default=None\n    Determines random number generation for adding small noise to\n    continuous variables in order to remove repeated values.\n    Pass an int for reproducible results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\nReturns\n-------\nmi : ndarray, shape (n_features,)\n    Estimated mutual information between each feature and the target in\n    nat units.\n\nNotes\n-----\n1. The term \"discrete features\" is used instead of naming them\n   \"categorical\", because it describes the essence more accurately.\n   For example, pixel intensities of an image are discrete features\n   (but hardly categorical) and you will get better results if mark them\n   as such. Also note, that treating a continuous variable as discrete and\n   vice versa will usually give incorrect results, so be attentive about\n   that.\n2. True mutual information can't be negative. If its estimate turns out\n   to be negative, it is replaced by zero.\n\nReferences\n----------\n.. [1] `Mutual Information\n       <https://en.wikipedia.org/wiki/Mutual_information>`_\n       on Wikipedia.\n.. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n       information\". Phys. Rev. E 69, 2004.\n.. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n       Data Sets\". PLoS ONE 9(2), 2014.\n.. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n       of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\n\nExamples\n--------\n>>> from sklearn.datasets import make_classification\n>>> from sklearn.feature_selection import mutual_info_classif\n>>> X, y = make_classification(\n...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n...     shuffle=False, random_state=42\n... )\n>>> mutual_info_classif(X, y)\narray([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,\n       0.     , 0.     , 0.     , 0.      , 0.        ])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Estimate mutual information for a continuous target variable.\n\nMutual information (MI) [1]_ between two random variables is a non-negative\nvalue, which measures the dependency between the variables. It is equal\nto zero if and only if two random variables are independent, and higher\nvalues mean higher dependency.\n\nThe function relies on nonparametric methods based on entropy estimation\nfrom k-nearest neighbors distances as described in [2]_ and [3]_. Both\nmethods are based on the idea originally proposed in [4]_.\n\nIt can be used for univariate features selection, read more in the\n:ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nX : array-like or sparse matrix, shape (n_samples, n_features)\n    Feature matrix.\n\ny : array-like of shape (n_samples,)\n    Target vector.\n\ndiscrete_features : {'auto', bool, array-like}, default='auto'\n    If bool, then determines whether to consider all features discrete\n    or continuous. If array, then it should be either a boolean mask\n    with shape (n_features,) or array with indices of discrete features.\n    If 'auto', it is assigned to False for dense `X` and to True for\n    sparse `X`.\n\nn_neighbors : int, default=3\n    Number of neighbors to use for MI estimation for continuous variables,\n    see [2]_ and [3]_. Higher values reduce variance of the estimation, but\n    could introduce a bias.\n\ncopy : bool, default=True\n    Whether to make a copy of the given data. If set to False, the initial\n    data will be overwritten.\n\nrandom_state : int, RandomState instance or None, default=None\n    Determines random number generation for adding small noise to\n    continuous variables in order to remove repeated values.\n    Pass an int for reproducible results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\nReturns\n-------\nmi : ndarray, shape (n_features,)\n    Estimated mutual information between each feature and the target in\n    nat units.\n\nNotes\n-----\n1. The term \"discrete features\" is used instead of naming them\n   \"categorical\", because it describes the essence more accurately.\n   For example, pixel intensities of an image are discrete features\n   (but hardly categorical) and you will get better results if mark them\n   as such. Also note, that treating a continuous variable as discrete and\n   vice versa will usually give incorrect results, so be attentive about\n   that.\n2. True mutual information can't be negative. If its estimate turns out\n   to be negative, it is replaced by zero.\n\nReferences\n----------\n.. [1] `Mutual Information\n       <https://en.wikipedia.org/wiki/Mutual_information>`_\n       on Wikipedia.\n.. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n       information\". Phys. Rev. E 69, 2004.\n.. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n       Data Sets\". PLoS ONE 9(2), 2014.\n.. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n       of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16\n\nExamples\n--------\n>>> from sklearn.datasets import make_regression\n>>> from sklearn.feature_selection import mutual_info_regression\n>>> X, y = make_regression(\n...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n... )\n>>> mutual_info_regression(X, y)\narray([0.1..., 2.6...  , 0.0...])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Recursive feature elimination with cross-validation to select features.\n\nThe number of features selected is tuned automatically by fitting an :class:`RFE`\nselector on the different cross-validation splits (provided by the `cv` parameter).\nThe performance of the :class:`RFE` selector are evaluated using `scorer` for\ndifferent number of selected features and aggregated together. Finally, the scores\nare averaged across folds and the number of features selected is set to the number\nof features that maximize the cross-validation score.\nSee glossary entry for :term:`cross-validation estimator`.\n\nRead more in the :ref:`User Guide <rfe>`.\n\nParameters\n----------\nestimator : ``Estimator`` instance\n    A supervised learning estimator with a ``fit`` method that provides\n    information about feature importance either through a ``coef_``\n    attribute or through a ``feature_importances_`` attribute.\n\nstep : int or float, default=1\n    If greater than or equal to 1, then ``step`` corresponds to the\n    (integer) number of features to remove at each iteration.\n    If within (0.0, 1.0), then ``step`` corresponds to the percentage\n    (rounded down) of features to remove at each iteration.\n    Note that the last iteration may remove fewer than ``step`` features in\n    order to reach ``min_features_to_select``.\n\nmin_features_to_select : int, default=1\n    The minimum number of features to be selected. This number of features\n    will always be scored, even if the difference between the original\n    feature count and ``min_features_to_select`` isn't divisible by\n    ``step``.\n\n    .. versionadded:: 0.20\n\ncv : int, cross-validation generator or an iterable, default=None\n    Determines the cross-validation splitting strategy.\n    Possible inputs for cv are:\n\n    - None, to use the default 5-fold cross-validation,\n    - integer, to specify the number of folds.\n    - :term:`CV splitter`,\n    - An iterable yielding (train, test) splits as arrays of indices.\n\n    For integer/None inputs, if ``y`` is binary or multiclass,\n    :class:`~sklearn.model_selection.StratifiedKFold` is used. If the\n    estimator is a classifier or if ``y`` is neither binary nor multiclass,\n    :class:`~sklearn.model_selection.KFold` is used.\n\n    Refer :ref:`User Guide <cross_validation>` for the various\n    cross-validation strategies that can be used here.\n\n    .. versionchanged:: 0.22\n        ``cv`` default value of None changed from 3-fold to 5-fold.\n\nscoring : str, callable or None, default=None\n    A string (see model evaluation documentation) or\n    a scorer callable object / function with signature\n    ``scorer(estimator, X, y)``.\n\nverbose : int, default=0\n    Controls verbosity of output.\n\nn_jobs : int or None, default=None\n    Number of cores to run in parallel while fitting across folds.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\n    .. versionadded:: 0.18\n\nimportance_getter : str or callable, default='auto'\n    If 'auto', uses the feature importance either through a `coef_`\n    or `feature_importances_` attributes of estimator.\n\n    Also accepts a string that specifies an attribute name/path\n    for extracting feature importance.\n    For example, give `regressor_.coef_` in case of\n    :class:`~sklearn.compose.TransformedTargetRegressor`  or\n    `named_steps.clf.feature_importances_` in case of\n    :class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n    If `callable`, overrides the default feature importance getter.\n    The callable is passed with the fitted estimator and it should\n    return importance for each feature.\n\n    .. versionadded:: 0.24\n\nAttributes\n----------\nclasses_ : ndarray of shape (n_classes,)\n    The classes labels. Only available when `estimator` is a classifier.\n\nestimator_ : ``Estimator`` instance\n    The fitted estimator used to select features.\n\ncv_results_ : dict of ndarrays\n    A dict with keys:\n\n    split(k)_test_score : ndarray of shape (n_subsets_of_features,)\n        The cross-validation scores across (k)th fold.\n\n    mean_test_score : ndarray of shape (n_subsets_of_features,)\n        Mean of scores over the folds.\n\n    std_test_score : ndarray of shape (n_subsets_of_features,)\n        Standard deviation of scores over the folds.\n\n    .. versionadded:: 1.0\n\nn_features_ : int\n    The number of selected features with cross-validation.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`. Only defined if the\n    underlying estimator exposes such an attribute when fit.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nranking_ : narray of shape (n_features,)\n    The feature ranking, such that `ranking_[i]`\n    corresponds to the ranking\n    position of the i-th feature.\n    Selected (i.e., estimated best)\n    features are assigned rank 1.\n\nsupport_ : ndarray of shape (n_features,)\n    The mask of selected features.\n\nSee Also\n--------\nRFE : Recursive feature elimination.\n\nNotes\n-----\nThe size of all values in ``cv_results_`` is equal to\n``ceil((n_features - min_features_to_select) / step) + 1``,\nwhere step is the number of features removed at each iteration.\n\nAllows NaN/Inf in the input if the underlying estimator does as well.\n\nReferences\n----------\n\n.. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n       for cancer classification using support vector machines\",\n       Mach. Learn., 46(1-3), 389--422, 2002.\n\nExamples\n--------\nThe following example shows how to retrieve the a-priori not known 5\ninformative features in the Friedman #1 dataset.\n\n>>> from sklearn.datasets import make_friedman1\n>>> from sklearn.feature_selection import RFECV\n>>> from sklearn.svm import SVR\n>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n>>> estimator = SVR(kernel=\"linear\")\n>>> selector = RFECV(estimator, step=1, cv=5)\n>>> selector = selector.fit(X, y)\n>>> selector.support_\narray([ True,  True,  True,  True,  True, False, False, False, False,\n       False])\n>>> selector.ranking_\narray([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Feature ranking with recursive feature elimination.\n\nGiven an external estimator that assigns weights to features (e.g., the\ncoefficients of a linear model), the goal of recursive feature elimination\n(RFE) is to select features by recursively considering smaller and smaller\nsets of features. First, the estimator is trained on the initial set of\nfeatures and the importance of each feature is obtained either through\nany specific attribute or callable.\nThen, the least important features are pruned from current set of features.\nThat procedure is recursively repeated on the pruned set until the desired\nnumber of features to select is eventually reached.\n\nRead more in the :ref:`User Guide <rfe>`.\n\nParameters\n----------\nestimator : ``Estimator`` instance\n    A supervised learning estimator with a ``fit`` method that provides\n    information about feature importance\n    (e.g. `coef_`, `feature_importances_`).\n\nn_features_to_select : int or float, default=None\n    The number of features to select. If `None`, half of the features are\n    selected. If integer, the parameter is the absolute number of features\n    to select. If float between 0 and 1, it is the fraction of features to\n    select.\n\n    .. versionchanged:: 0.24\n       Added float values for fractions.\n\nstep : int or float, default=1\n    If greater than or equal to 1, then ``step`` corresponds to the\n    (integer) number of features to remove at each iteration.\n    If within (0.0, 1.0), then ``step`` corresponds to the percentage\n    (rounded down) of features to remove at each iteration.\n\nverbose : int, default=0\n    Controls verbosity of output.\n\nimportance_getter : str or callable, default='auto'\n    If 'auto', uses the feature importance either through a `coef_`\n    or `feature_importances_` attributes of estimator.\n\n    Also accepts a string that specifies an attribute name/path\n    for extracting feature importance (implemented with `attrgetter`).\n    For example, give `regressor_.coef_` in case of\n    :class:`~sklearn.compose.TransformedTargetRegressor`  or\n    `named_steps.clf.feature_importances_` in case of\n    class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n    If `callable`, overrides the default feature importance getter.\n    The callable is passed with the fitted estimator and it should\n    return importance for each feature.\n\n    .. versionadded:: 0.24\n\nAttributes\n----------\nclasses_ : ndarray of shape (n_classes,)\n    The classes labels. Only available when `estimator` is a classifier.\n\nestimator_ : ``Estimator`` instance\n    The fitted estimator used to select features.\n\nn_features_ : int\n    The number of selected features.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`. Only defined if the\n    underlying estimator exposes such an attribute when fit.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nranking_ : ndarray of shape (n_features,)\n    The feature ranking, such that ``ranking_[i]`` corresponds to the\n    ranking position of the i-th feature. Selected (i.e., estimated\n    best) features are assigned rank 1.\n\nsupport_ : ndarray of shape (n_features,)\n    The mask of selected features.\n\nSee Also\n--------\nRFECV : Recursive feature elimination with built-in cross-validated\n    selection of the best number of features.\nSelectFromModel : Feature selection based on thresholds of importance\n    weights.\nSequentialFeatureSelector : Sequential cross-validation based feature\n    selection. Does not rely on importance weights.\n\nNotes\n-----\nAllows NaN/Inf in the input if the underlying estimator does as well.\n\nReferences\n----------\n\n.. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n       for cancer classification using support vector machines\",\n       Mach. Learn., 46(1-3), 389--422, 2002.\n\nExamples\n--------\nThe following example shows how to retrieve the 5 most informative\nfeatures in the Friedman #1 dataset.\n\n>>> from sklearn.datasets import make_friedman1\n>>> from sklearn.feature_selection import RFE\n>>> from sklearn.svm import SVR\n>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n>>> estimator = SVR(kernel=\"linear\")\n>>> selector = RFE(estimator, n_features_to_select=5, step=1)\n>>> selector = selector.fit(X, y)\n>>> selector.support_\narray([ True,  True,  True,  True,  True, False, False, False, False,\n       False])\n>>> selector.ranking_\narray([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFdrMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Filter: Select the p-values for an estimated false discovery rate.\n\nThis uses the Benjamini-Hochberg procedure. ``alpha`` is an upper bound\non the expected false discovery rate.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues).\n    Default is f_classif (see below \"See Also\"). The default function only\n    works with classification tasks.\n\nalpha : float, default=5e-2\n    The highest uncorrected p-value for features to keep.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nmutual_info_classif : Mutual information for a discrete target.\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\nmutual_info_regression : Mutual information for a continuous target.\nSelectPercentile : Select features based on percentile of the highest\n    scores.\nSelectKBest : Select features based on the k highest scores.\nSelectFpr : Select features based on a false positive rate test.\nSelectFwe : Select features based on family-wise error rate.\nGenericUnivariateSelect : Univariate feature selector with configurable\n    mode.\n\nReferences\n----------\nhttps://en.wikipedia.org/wiki/False_discovery_rate\n\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFdr, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFdr(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 16)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFprMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Filter: Select the pvalues below alpha based on a FPR test.\n\nFPR test stands for False Positive Rate test. It controls the total\namount of false detections.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues).\n    Default is f_classif (see below \"See Also\"). The default function only\n    works with classification tasks.\n\nalpha : float, default=5e-2\n    Features with p-values less than `alpha` are selected.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nmutual_info_classif: Mutual information for a discrete target.\nf_regression : F-value between label/feature for regression tasks.\nmutual_info_regression : Mutual information for a continuous target.\nSelectPercentile : Select features based on percentile of the highest\n    scores.\nSelectKBest : Select features based on the k highest scores.\nSelectFdr : Select features based on an estimated false discovery rate.\nSelectFwe : Select features based on family-wise error rate.\nGenericUnivariateSelect : Univariate feature selector with configurable\n    mode.\n\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFpr, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFpr(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 16)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Meta-transformer for selecting features based on importance weights.\n\n.. versionadded:: 0.17\n\nRead more in the :ref:`User Guide <select_from_model>`.\n\nParameters\n----------\nestimator : object\n    The base estimator from which the transformer is built.\n    This can be both a fitted (if ``prefit`` is set to True)\n    or a non-fitted estimator. The estimator should have a\n    ``feature_importances_`` or ``coef_`` attribute after fitting.\n    Otherwise, the ``importance_getter`` parameter should be used.\n\nthreshold : str or float, default=None\n    The threshold value to use for feature selection. Features whose\n    absolute importance value is greater or equal are kept while the others\n    are discarded. If \"median\" (resp. \"mean\"), then the ``threshold`` value\n    is the median (resp. the mean) of the feature importances. A scaling\n    factor (e.g., \"1.25*mean\") may also be used. If None and if the\n    estimator has a parameter penalty set to l1, either explicitly\n    or implicitly (e.g, Lasso), the threshold used is 1e-5.\n    Otherwise, \"mean\" is used by default.\n\nprefit : bool, default=False\n    Whether a prefit model is expected to be passed into the constructor\n    directly or not.\n    If `True`, `estimator` must be a fitted estimator.\n    If `False`, `estimator` is fitted and updated by calling\n    `fit` and `partial_fit`, respectively.\n\nnorm_order : non-zero int, inf, -inf, default=1\n    Order of the norm used to filter the vectors of coefficients below\n    ``threshold`` in the case where the ``coef_`` attribute of the\n    estimator is of dimension 2.\n\nmax_features : int, callable, default=None\n    The maximum number of features to select.\n\n    - If an integer, then it specifies the maximum number of features to\n      allow.\n    - If a callable, then it specifies how to calculate the maximum number of\n      features allowed by using the output of `max_features(X)`.\n    - If `None`, then all features are kept.\n\n    To only select based on ``max_features``, set ``threshold=-np.inf``.\n\n    .. versionadded:: 0.20\n    .. versionchanged:: 1.1\n       `max_features` accepts a callable.\n\nimportance_getter : str or callable, default='auto'\n    If 'auto', uses the feature importance either through a ``coef_``\n    attribute or ``feature_importances_`` attribute of estimator.\n\n    Also accepts a string that specifies an attribute name/path\n    for extracting feature importance (implemented with `attrgetter`).\n    For example, give `regressor_.coef_` in case of\n    :class:`~sklearn.compose.TransformedTargetRegressor`  or\n    `named_steps.clf.feature_importances_` in case of\n    :class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n    If `callable`, overrides the default feature importance getter.\n    The callable is passed with the fitted estimator and it should\n    return importance for each feature.\n\n    .. versionadded:: 0.24\n\nAttributes\n----------\nestimator_ : estimator\n    The base estimator from which the transformer is built. This attribute\n    exist only when `fit` has been called.\n\n    - If `prefit=True`, it is a deep copy of `estimator`.\n    - If `prefit=False`, it is a clone of `estimator` and fit on the data\n      passed to `fit` or `partial_fit`.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`. Only defined if the\n    underlying estimator exposes such an attribute when fit.\n\n    .. versionadded:: 0.24\n\nmax_features_ : int\n    Maximum number of features calculated during :term:`fit`. Only defined\n    if the ``max_features`` is not `None`.\n\n    - If `max_features` is an `int`, then `max_features_ = max_features`.\n    - If `max_features` is a callable, then `max_features_ = max_features(X)`.\n\n    .. versionadded:: 1.1\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nthreshold_ : float\n    The threshold value used for feature selection.\n\nSee Also\n--------\nRFE : Recursive feature elimination based on importance weights.\nRFECV : Recursive feature elimination with built-in cross-validated\n    selection of the best number of features.\nSequentialFeatureSelector : Sequential cross-validation based feature\n    selection. Does not rely on importance weights.\n\nNotes\n-----\nAllows NaN/Inf in the input if the underlying estimator does as well.\n\nExamples\n--------\n>>> from sklearn.feature_selection import SelectFromModel\n>>> from sklearn.linear_model import LogisticRegression\n>>> X = [[ 0.87, -1.34,  0.31 ],\n...      [-2.79, -0.02, -0.85 ],\n...      [-1.34, -0.48, -2.55 ],\n...      [ 1.92,  1.48,  0.65 ]]\n>>> y = [0, 1, 0, 1]\n>>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n>>> selector.estimator_.coef_\narray([[-0.3252...,  0.8345...,  0.4976...]])\n>>> selector.threshold_\n0.55249...\n>>> selector.get_support()\narray([False,  True, False])\n>>> selector.transform(X)\narray([[-1.34],\n       [-0.02],\n       [-0.48],\n       [ 1.48]])\n\nUsing a callable to create a selector that can use no more than half\nof the input features.\n\n>>> def half_callable(X):\n...     return round(len(X[0]) / 2)\n>>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n...                                 max_features=half_callable)\n>>> _ = half_selector.fit(X, y)\n>>> half_selector.max_features_\n2"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFweMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Filter: Select the p-values corresponding to Family-wise error rate.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues).\n    Default is f_classif (see below \"See Also\"). The default function only\n    works with classification tasks.\n\nalpha : float, default=5e-2\n    The highest uncorrected p-value for features to keep.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\nSelectPercentile : Select features based on percentile of the highest\n    scores.\nSelectKBest : Select features based on the k highest scores.\nSelectFpr : Select features based on a false positive rate test.\nSelectFdr : Select features based on an estimated false discovery rate.\nGenericUnivariateSelect : Univariate feature selector with configurable\n    mode.\n\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFwe, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFwe(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 15)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectKBestMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Select features according to the k highest scores.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues) or a single array with scores.\n    Default is f_classif (see below \"See Also\"). The default function only\n    works with classification tasks.\n\n    .. versionadded:: 0.18\n\nk : int or \"all\", default=10\n    Number of top features to select.\n    The \"all\" option bypasses selection, for use in a parameter search.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores, None if `score_func` returned only scores.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif: ANOVA F-value between label/feature for classification tasks.\nmutual_info_classif: Mutual information for a discrete target.\nchi2: Chi-squared stats of non-negative features for classification tasks.\nf_regression: F-value between label/feature for regression tasks.\nmutual_info_regression: Mutual information for a continuous target.\nSelectPercentile: Select features based on percentile of the highest\n    scores.\nSelectFpr : Select features based on a false positive rate test.\nSelectFdr : Select features based on an estimated false discovery rate.\nSelectFwe : Select features based on family-wise error rate.\nGenericUnivariateSelect : Univariate feature selector with configurable\n    mode.\n\nNotes\n-----\nTies between features with equal scores will be broken in an unspecified\nway.\n\nThis filter supports unsupervised feature selection that only requests `X` for\ncomputing the scores.\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.feature_selection import SelectKBest, chi2\n>>> X, y = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n>>> X_new.shape\n(1797, 20)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectPercentileMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Select features according to a percentile of the highest scores.\n\nRead more in the :ref:`User Guide <univariate_feature_selection>`.\n\nParameters\n----------\nscore_func : callable, default=f_classif\n    Function taking two arrays X and y, and returning a pair of arrays\n    (scores, pvalues) or a single array with scores.\n    Default is f_classif (see below \"See Also\"). The default function only\n    works with classification tasks.\n\n    .. versionadded:: 0.18\n\npercentile : int, default=10\n    Percent of features to keep.\n\nAttributes\n----------\nscores_ : array-like of shape (n_features,)\n    Scores of features.\n\npvalues_ : array-like of shape (n_features,)\n    p-values of feature scores, None if `score_func` returned only scores.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nf_classif : ANOVA F-value between label/feature for classification tasks.\nmutual_info_classif : Mutual information for a discrete target.\nchi2 : Chi-squared stats of non-negative features for classification tasks.\nf_regression : F-value between label/feature for regression tasks.\nmutual_info_regression : Mutual information for a continuous target.\nSelectKBest : Select features based on the k highest scores.\nSelectFpr : Select features based on a false positive rate test.\nSelectFdr : Select features based on an estimated false discovery rate.\nSelectFwe : Select features based on family-wise error rate.\nGenericUnivariateSelect : Univariate feature selector with configurable\n    mode.\n\nNotes\n-----\nTies between features with equal scores will be broken in an unspecified\nway.\n\nThis filter supports unsupervised feature selection that only requests `X` for\ncomputing the scores.\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.feature_selection import SelectPercentile, chi2\n>>> X, y = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n>>> X_new.shape\n(1797, 7)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Transformer that performs Sequential Feature Selection.\n\nThis Sequential Feature Selector adds (forward selection) or\nremoves (backward selection) features to form a feature subset in a\ngreedy fashion. At each stage, this estimator chooses the best feature to\nadd or remove based on the cross-validation score of an estimator. In\nthe case of unsupervised learning, this Sequential Feature Selector\nlooks only at the features (X), not the desired outputs (y).\n\nRead more in the :ref:`User Guide <sequential_feature_selection>`.\n\n.. versionadded:: 0.24\n\nParameters\n----------\nestimator : estimator instance\n    An unfitted estimator.\n\nn_features_to_select : \"auto\", int or float, default=\"auto\"\n    If `\"auto\"`, the behaviour depends on the `tol` parameter:\n\n    - if `tol` is not `None`, then features are selected while the score\n      change does not exceed `tol`.\n    - otherwise, half of the features are selected.\n\n    If integer, the parameter is the absolute number of features to select.\n    If float between 0 and 1, it is the fraction of features to select.\n\n    .. versionadded:: 1.1\n       The option `\"auto\"` was added in version 1.1.\n\n    .. versionchanged:: 1.3\n       The default changed from `\"warn\"` to `\"auto\"` in 1.3.\n\ntol : float, default=None\n    If the score is not incremented by at least `tol` between two\n    consecutive feature additions or removals, stop adding or removing.\n\n    `tol` can be negative when removing features using `direction=\"backward\"`.\n    It can be useful to reduce the number of features at the cost of a small\n    decrease in the score.\n\n    `tol` is enabled only when `n_features_to_select` is `\"auto\"`.\n\n    .. versionadded:: 1.1\n\ndirection : {'forward', 'backward'}, default='forward'\n    Whether to perform forward selection or backward selection.\n\nscoring : str or callable, default=None\n    A single str (see :ref:`scoring_parameter`) or a callable\n    (see :ref:`scoring`) to evaluate the predictions on the test set.\n\n    NOTE that when using a custom scorer, it should return a single\n    value.\n\n    If None, the estimator's score method is used.\n\ncv : int, cross-validation generator or an iterable, default=None\n    Determines the cross-validation splitting strategy.\n    Possible inputs for cv are:\n\n    - None, to use the default 5-fold cross validation,\n    - integer, to specify the number of folds in a `(Stratified)KFold`,\n    - :term:`CV splitter`,\n    - An iterable yielding (train, test) splits as arrays of indices.\n\n    For integer/None inputs, if the estimator is a classifier and ``y`` is\n    either binary or multiclass,\n    :class:`~sklearn.model_selection.StratifiedKFold` is used. In all other\n    cases, :class:`~sklearn.model_selection.KFold` is used. These splitters\n    are instantiated with `shuffle=False` so the splits will be the same\n    across calls.\n\n    Refer :ref:`User Guide <cross_validation>` for the various\n    cross-validation strategies that can be used here.\n\nn_jobs : int, default=None\n    Number of jobs to run in parallel. When evaluating a new feature to\n    add or remove, the cross-validation procedure is parallel over the\n    folds.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nAttributes\n----------\nn_features_in_ : int\n    Number of features seen during :term:`fit`. Only defined if the\n    underlying estimator exposes such an attribute when fit.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_features_to_select_ : int\n    The number of features that were selected.\n\nsupport_ : ndarray of shape (n_features,), dtype=bool\n    The mask of selected features.\n\nSee Also\n--------\nGenericUnivariateSelect : Univariate feature selector with configurable\n    strategy.\nRFE : Recursive feature elimination based on importance weights.\nRFECV : Recursive feature elimination based on importance weights, with\n    automatic selection of the number of features.\nSelectFromModel : Feature selection based on thresholds of importance\n    weights.\n\nExamples\n--------\n>>> from sklearn.feature_selection import SequentialFeatureSelector\n>>> from sklearn.neighbors import KNeighborsClassifier\n>>> from sklearn.datasets import load_iris\n>>> X, y = load_iris(return_X_y=True)\n>>> knn = KNeighborsClassifier(n_neighbors=3)\n>>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n>>> sfs.fit(X, y)\nSequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3),\n                          n_features_to_select=3)\n>>> sfs.get_support()\narray([ True, False,  True,  True])\n>>> sfs.transform(X).shape\n(150, 3)"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VarianceThresholdMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#Class" ],
  "http://www.w3.org/2000/01/rdf-schema#comment" : [ {
    "@value" : "Feature selector that removes all low-variance features.\n\nThis feature selection algorithm looks only at the features (X), not the\ndesired outputs (y), and can thus be used for unsupervised learning.\n\nRead more in the :ref:`User Guide <variance_threshold>`.\n\nParameters\n----------\nthreshold : float, default=0\n    Features with a training-set variance lower than this threshold will\n    be removed. The default is to keep all features with non-zero variance,\n    i.e. remove the features that have the same value in all samples.\n\nAttributes\n----------\nvariances_ : array, shape (n_features,)\n    Variances of individual features.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nSelectFromModel: Meta-transformer for selecting features based on\n    importance weights.\nSelectPercentile : Select features according to a percentile of the highest\n    scores.\nSequentialFeatureSelector : Transformer that performs Sequential Feature\n    Selection.\n\nNotes\n-----\nAllows NaN in the input.\nRaises ValueError if no feature in X meets the variance threshold.\n\nExamples\n--------\nThe following dataset has integer features, two of which are the same\nin every sample. These are removed with the default setting for threshold::\n\n    >>> from sklearn.feature_selection import VarianceThreshold\n    >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n    >>> selector = VarianceThreshold()\n    >>> selector.fit_transform(X)\n    array([[2, 0],\n           [1, 4],\n           [1, 1]])"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subClassOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelectionModule"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasFeatureSelectionMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#ObjectProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FeatureSelection"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Chi2Method"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FRegressionMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GenericUnivariateSelectMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFdrMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFprMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFweMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectKBestMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectPercentileMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VarianceThresholdMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPrepareTransformerMethod"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFdrMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFprMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFweMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCenter",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#boolean"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#boolean"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCv",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDirection",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDiscreteFeatures",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#boolean"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEstimator",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#boolean"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamImportanceGetter",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectKBestMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMaxFeatures",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMinFeaturesToSelect",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMode",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GenericUnivariateSelectMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNFeaturesToSelect",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNNeighbors",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormOrder",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamParam",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GenericUnivariateSelectMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPercentile",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectPercentileMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPrefit",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#boolean"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoClassifMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoRegressionMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GenericUnivariateSelectMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFdrMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFprMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFweMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectKBestMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectPercentileMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamStep",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamThreshold",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SelectFromModelMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VarianceThresholdMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#string"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamTol",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SequentialFeatureSelectorMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#float"
  }, {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamVerbose",
  "@type" : [ "http://www.w3.org/2002/07/owl#DatatypeProperty" ],
  "http://www.w3.org/2000/01/rdf-schema#domain" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFECVMethod"
  }, {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RFEMethod"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#range" : [ {
    "@id" : "http://www.w3.org/2001/XMLSchema#int"
  } ],
  "http://www.w3.org/2000/01/rdf-schema#subPropertyOf" : [ {
    "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"
  } ]
}, {
  "@id" : "https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPrepareTransformerMethod",
  "@type" : [ "http://www.w3.org/2002/07/owl#ObjectProperty" ]
} ]